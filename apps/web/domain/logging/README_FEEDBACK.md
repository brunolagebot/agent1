# Sistema de Feedback e Melhoria Cont√≠nua

## Objetivo
Coletar feedback do usu√°rio em 5 n√≠veis para melhorar respostas do modelo atrav√©s de fine-tuning.

## Como Funciona

### 1. Interface (5 Emojis)
Ap√≥s cada resposta do assistente, aparecem 5 bot√µes:
- üòû (1 estrela) - Muito ruim
- üòï (2 estrelas) - Ruim
- üòê (3 estrelas) - Regular
- üôÇ (4 estrelas) - Bom
- üòç (5 estrelas) - Excelente

### 2. Armazenamento
Feedback salvo em `messages.feedback_score`:
```sql
ALTER TABLE messages
ADD COLUMN feedback_score INTEGER CHECK (feedback_score BETWEEN 1 AND 5),
ADD COLUMN feedback_comment TEXT,
ADD COLUMN feedback_at TIMESTAMP;
```

### 3. An√°lise
View `feedback_analysis` agrega por score e role:
```sql
SELECT feedback_score, COUNT(*), AVG(response_length), user_role
FROM messages
WHERE role = 'assistant' AND feedback_score IS NOT NULL
GROUP BY feedback_score, user_role;
```

## APIs

### POST /api/messages/feedback
```bash
curl -X POST http://web.localhost/api/messages/feedback \
  -H "Content-Type: application/json" \
  -d '{"messageId": "msg-123", "score": 5, "comment": "√ìtima resposta!"}'
```

### GET /api/messages/feedback-stats
```bash
curl http://web.localhost/api/messages/feedback-stats
```

## Uso para Fine-tuning

### 1. Exportar conversas com alto score
```sql
SELECT c.id, m.content, m.feedback_score
FROM messages m
JOIN conversations c ON m.conversation_id = c.id
WHERE m.feedback_score >= 4
  AND c.approved_for_training = TRUE
ORDER BY m.feedback_score DESC, c.updated_at DESC;
```

### 2. Priorizar no dataset
```python
# Exemplo: ponderar por feedback
import json

with open('training.jsonl') as f:
    data = []
    for line in f:
        conv = json.loads(line)
        # Duplicar conversas de alta qualidade
        if conv.get('avg_score', 0) >= 4:
            data.extend([conv] * 2)  # 2x weight
        else:
            data.append(conv)

# Salvar dataset ponderado
with open('training_weighted.jsonl', 'w') as f:
    for item in data:
        f.write(json.dumps(item) + '\n')
```

### 3. Filtrar ruins
Conversas com m√©dia de feedback < 2 podem ser exclu√≠das ou revisadas antes do treino.

## Barra de Progresso

### Estados Visuais
Durante processamento de mensagem, mostra:
1. **20%** - üîç Buscando contexto em documentos
2. **50%** - ü§ñ Gerando resposta (LLM processando)
3. **80%** - ‚ú® Finalizando
4. **100%** - ‚úÖ Pronto!

Durante upload de documento:
1. üìÑ Lendo arquivo
2. ‚úÇÔ∏è Dividindo em chunks
3. üß† Gerando embeddings
4. ‚úÖ Processado (N chunks)

## Benef√≠cios

1. **Melhoria Cont√≠nua**: Modelo aprende com feedback real
2. **Prioriza√ß√£o**: Treinar com exemplos de alta qualidade
3. **Detec√ß√£o de Problemas**: Identificar tipos de pergunta que funcionam mal
4. **UX Transparente**: Usu√°rio v√™ o que est√° acontecendo
5. **Timeout Aumentado**: 60s para respostas complexas

## Pr√≥ximos Passos

- [ ] Coment√°rios textuais no feedback (al√©m do score)
- [ ] Dashboard de analytics de feedback
- [ ] A/B testing de prompts baseado em feedback
- [ ] Alertas autom√°ticos para score m√©dio < 3

